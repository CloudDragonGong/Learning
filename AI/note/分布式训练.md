[书籍](https://zh.d2l.ai/chapter_computational-performance/parameterserver.html)

# 分布式计算

![image-20230708011851587](%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/image-20230708011851587.png)

# GPU机器架构

![image-20230708011930459](%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/image-20230708011930459.png)

尽量减少机器和机器之间的通信，才能发挥出性能

# 下面是个减少机器之间通信的例子

![image-20230708012103239](%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/image-20230708012103239.png)

# 分布式训练例子

![image-20230708012312550](%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/image-20230708012312550.png)

- 先从样本发数据
- 然后计算梯度
- 每台机器都相加
- 加完后就发送给参数服务器，然后做参数更新

# 同步SGD

![image-20230708012515593](%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/image-20230708012515593.png)

# 性能

![image-20230708012756118](%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/image-20230708012756118.png)

- 这里的max指的是异步的SGD，同步不可能



# 性能的权衡

小的batch-size意味着多个epoch

![image-20230708013041099](%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/image-20230708013041099.png)

# 实践里面的建议

![image-20230708013114256](%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/image-20230708013114256.png)

- 其中优化算法是一个学问，可以学习

# 总结

![image-20230708013413160](%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/image-20230708013413160.png)

- 分布式模型并行不多